<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>introduction</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<h1 id="introduction-to-qseabattle">Introduction to QSeaBattle</h1>
<h2 id="what-is-qseabattle">What is QSeaBattle?</h2>
<p>QSeaBattle is a collaborative quantum game framework that explores
the boundaries between classical and quantum information processing. It
provides a testbed for investigating how quantum-inspired correlations
can enable coordination between agents with limited classical
communication.</p>
<h3 id="the-core-challenge">The Core Challenge</h3>
<p>In QSeaBattle, two players work together to solve a coordination
problem:</p>
<ul>
<li><strong>Player A</strong> observes a binary battlefield (an <span
class="math inline">\(n \times n\)</span> grid of 0s and 1s)</li>
<li><strong>Player A</strong> can send only <span
class="math inline">\(m\)</span> classical bits to <strong>Player
B</strong> (where <span class="math inline">\(m\)</span> is much smaller
than <span class="math inline">\(n^2\)</span>)</li>
<li><strong>Player B</strong> sees only a gun position and must decide
whether to shoot</li>
<li>Success means correctly guessing the value at the gun position</li>
</ul>
<p>This setup mirrors fundamental questions in quantum information
theory: How much can two parties coordinate when restricted to limited
classical communication?</p>
<h2 id="why-qseabattle">Why QSeaBattle?</h2>
<h3 id="scientific-motivation">Scientific Motivation</h3>
<p>QSeaBattle was developed to bridge several areas of research:</p>
<p><strong>1. Quantum Information Theory</strong></p>
<ul>
<li>Explores concepts like shared randomness and quantum
correlations</li>
<li>Investigates information-theoretic limits (Information
Causality)</li>
<li>Provides concrete implementations of abstract quantum protocols</li>
</ul>
<p><strong>2. Multi-Agent Reinforcement Learning</strong></p>
<ul>
<li>Studies emergent communication in cooperative settings</li>
<li>Tests architectures like DIAL (Differentiable Inter-Agent
Learning)</li>
<li>Examines the role of shared resources in coordination</li>
</ul>
<p><strong>3. Neural-Symbolic Integration</strong></p>
<ul>
<li>Combines algorithmic knowledge (classical quantum protocols) with
learning</li>
<li>Uses imitation learning to bootstrap neural agents from known
strategies</li>
<li>Investigates how neural networks can discover or approximate quantum
advantages</li>
</ul>
<h3 id="educational-value">Educational Value</h3>
<p>QSeaBattle serves as an accessible introduction to:</p>
<ul>
<li>Quantum game theory without requiring quantum hardware</li>
<li>Information-theoretic constraints in communication</li>
<li>The relationship between correlation, communication, and
computation</li>
<li>Modern deep learning architectures for multi-agent systems</li>
</ul>
<h2 id="the-game-mechanics">The Game Mechanics</h2>
<h3 id="basic-setup">Basic Setup</h3>
<p>A single game of QSeaBattle proceeds as follows:</p>
<p><strong>1. Field Generation</strong></p>
<p>A battlefield of size <span class="math inline">\(n \cdot n\)</span>
is created, where each cell independently has probability <span
class="math inline">\(p\)</span> of containing an enemy (value 1)</p>
<p><strong>2. Gun Placement</strong></p>
<p>A gun position is randomly selected from the <span
class="math inline">\(n^2\)</span> possible locations</p>
<p><strong>3. Player A Decision</strong></p>
<ul>
<li>Observes the entire battlefield</li>
<li>Generates an <span class="math inline">\(m\)</span>-bit
communication message</li>
<li>This message passes through a noisy channel with bit-flip
probability <span class="math inline">\(c\)</span></li>
</ul>
<p><strong>4. Player B Decision</strong></p>
<ul>
<li>Sees only the gun position</li>
<li>Receives the (possibly noisy) communication</li>
<li>Decides to shoot (1) or not shoot (0)</li>
</ul>
<p><strong>5. Evaluation</strong></p>
<p>The decision is correct if:</p>
<ul>
<li>Shoot when there is an enemy at that position, or</li>
<li>Do not shoot when that position is empty</li>
</ul>
<h3 id="game-parameters">Game Parameters</h3>
<p>The game is configured through a GameLayout object with the following
parameters:</p>
<table>
<colgroup>
<col style="width: 25%" />
<col style="width: 8%" />
<col style="width: 42%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr>
<th>Parameter</th>
<th>Symbol</th>
<th>Description</th>
<th>Typical Values</th>
</tr>
</thead>
<tbody>
<tr>
<td>field_size</td>
<td><span class="math inline">\(n\)</span></td>
<td>Dimension of battlefield</td>
<td>4, 8, 16, 32, 64</td>
</tr>
<tr>
<td>comms_size</td>
<td><span class="math inline">\(m\)</span></td>
<td>Number of communication bits</td>
<td>1 to 16</td>
</tr>
<tr>
<td>enemy_probability</td>
<td><span class="math inline">\(p\)</span></td>
<td>Probability of enemy per cell</td>
<td>0.5</td>
</tr>
<tr>
<td>channel_noise</td>
<td><span class="math inline">\(c\)</span></td>
<td>Bit-flip probability</td>
<td>0.0 to 0.3</td>
</tr>
</tbody>
</table>
<h3 id="performance-metrics">Performance Metrics</h3>
<p>Player performance is measured by:</p>
<ul>
<li><strong>Win Rate</strong>: Proportion of correct decisions across
many games</li>
<li><strong>Comparison to Baselines</strong>: Simple random guessing,
majority voting, classical protocols</li>
<li><strong>Information-Theoretic Bounds</strong>: Limits imposed by
Information Causality given <span class="math inline">\(m\)</span> and
<span class="math inline">\(c\)</span></li>
</ul>
<h2 id="architecture-overview">Architecture Overview</h2>
<p>QSeaBattle is organized into several layers, from basic game
infrastructure to advanced trainable agents.</p>
<h3 id="layer-1-core-game-infrastructure">Layer 1: Core Game
Infrastructure</h3>
<p>The foundation provides the essential game mechanics:</p>
<ul>
<li><strong>GameLayout</strong>: Configuration parameters</li>
<li><strong>GameEnv</strong>: Battlefield generation and evaluation</li>
<li><strong>Players</strong>: Base class for player implementations</li>
<li><strong>PlayerA/PlayerB</strong>: Individual player interfaces</li>
<li><strong>Game</strong>: Single game execution</li>
<li><strong>Tournament</strong>: Multiple game execution and
logging</li>
<li><strong>TournamentLog</strong>: Data collection and analysis</li>
</ul>
<p>Purpose: Ensures consistent game execution, reproducibility, and data
collection across all player types.</p>
<h3 id="layer-2-deterministic-players">Layer 2: Deterministic
Players</h3>
<p>Hand-crafted strategies that serve as baselines:</p>
<ul>
<li><strong>SimplePlayers</strong>: Direct communication of first <span
class="math inline">\(m\)</span> cells</li>
<li><strong>MajorityPlayers</strong>: Segment-wise majority voting
strategy</li>
</ul>
<p>Purpose: Provide interpretable baselines and verify game mechanics
are working correctly.</p>
<h3 id="layer-3-classical-neural-players">Layer 3: Classical Neural
Players</h3>
<p>Trainable agents without shared randomness:</p>
<p><strong>NeuralNetPlayers</strong>: Two independent neural
networks</p>
<ul>
<li>Model A: field to communication logits</li>
<li>Model B: gun and communication to shoot logit</li>
</ul>
<p>Features:</p>
<ul>
<li>Can be trained by imitation (supervised learning on baseline
strategies)</li>
<li>Can be trained by reinforcement learning (self-play with policy
gradients)</li>
<li>Provides comparison point for quantum-inspired approaches</li>
</ul>
<p>Purpose: Establish what purely classical learning can achieve within
information-theoretic constraints.</p>
<h3 id="layer-4-assisted-players-classical-quantum-simulation">Layer 4:
Assisted Players (Classical Quantum Simulation)</h3>
<p>Deterministic algorithms that simulate quantum correlations using
shared randomness:</p>
<p><strong>AssistedPlayers</strong>: Classical implementation of quantum
protocols</p>
<ul>
<li><strong>SharedRandomness</strong>: Simulates entangled
measurements</li>
<li><strong>AssistedPlayerA</strong>: Hierarchical measurement
strategy</li>
<li><strong>AssistedPlayerB</strong>: Complementary measurement
strategy</li>
</ul>
<p>Key Concept: These players share access to pre-established random
bits that are correlated in a specific way (controlled by parameter
<span class="math inline">\(p_{\mathrm{high}}\)</span>). This
correlation mimics quantum entanglement and enables coordination beyond
classical limits.</p>
<p>Purpose: Demonstrate the target behavior that trainable
quantum-inspired agents should learn.</p>
<h3 id="layer-5-trainable-assisted-players">Layer 5: Trainable Assisted
Players</h3>
<p>Neural implementations that combine learning with quantum-inspired
structure:</p>
<p><strong>TrainableAssistedPlayers</strong>: Neural networks with
shared randomness layers</p>
<p><strong>Linear Architecture:</strong></p>
<ul>
<li>LinMeasurementLayerA/B: Learn measurement choices</li>
<li>SharedRandomnessLayer: Fixed correlation (differentiable)</li>
<li>LinCombineLayerA/B: Learn how to use outcomes</li>
<li>Single shared resource per decision</li>
</ul>
<p><strong>Pyramid Architecture:</strong></p>
<ul>
<li>PyrMeasurementLayerA/B: Multi-level measurement</li>
<li>Multiple SharedRandomnessLayers (one per level)</li>
<li>PyrCombineLayerA/B: Hierarchical combination</li>
<li><span class="math inline">\(\log(n^2)\)</span> shared resources per
decision</li>
</ul>
<p><strong>Training Approaches:</strong></p>
<ol type="1">
<li>Imitation Learning: Train on synthetic datasets generated by
classical assisted algorithms</li>
<li>Differentiable Communication: Use DRU (Discretize/Regularize Unit)
for end-to-end gradient flow</li>
<li>Reinforcement Learning: Policy gradient methods with shared
randomness</li>
</ol>
<p>Purpose: Enable neural networks to discover and improve
quantum-inspired strategies through learning.</p>
<h3 id="supporting-utilities">Supporting Utilities</h3>
<p>Several utility modules provide consistent implementations across the
framework:</p>
<ul>
<li><strong>logit_utils</strong>: Stable logit/probability
conversions</li>
<li><strong>dru_utils</strong>: Differentiable communication (DIAL)</li>
<li><strong>reference_performance_utils</strong>: Analytic baselines and
bounds</li>
<li><strong>imitation_utils</strong>: Synthetic dataset generation</li>
</ul>
<h2 id="information-flow-in-qseabattle">Information Flow in
QSeaBattle</h2>
<p>The key architectural pattern is how information flows between
players.</p>
<h3 id="classical-neural-players">Classical Neural Players</h3>
<p>Flow diagram:</p>
<pre class="text"><code>Field → Model A → Communication → Model B → Shoot Decision
        ↓                           ↑
      [Loss A]                   [Loss B]</code></pre>
<p>Characteristics:</p>
<ul>
<li>Independent training possible</li>
<li>Communication is a bottleneck (<span
class="math inline">\(m\)</span> bits)</li>
<li>Limited by classical information theory</li>
</ul>
<h3 id="trainable-assisted-players">Trainable Assisted Players</h3>
<p>Flow diagram:</p>
<pre class="text"><code>Field → Measurement A → Shared Randomness ← Measurement B ← Gun
              ↓              ↓    ↓              ↓
          Outcome A      Correlation      Outcome B
              ↓                                   ↓
        Combine A → Communication → Combine B → Shoot
              ↓                                   ↓
           [Loss A]                          [Loss B]</code></pre>
<p>Characteristics:</p>
<ul>
<li>Measurements are learned (neural layers)</li>
<li>Shared randomness is fixed (simulates physics)</li>
<li>Combine operations are learned (neural layers)</li>
<li>Key advantage: Correlation is outside the <span
class="math inline">\(m\)</span>-bit channel</li>
<li>Can exceed classical limits if trained correctly</li>
</ul>
<h2 id="data-flow-and-reproducibility">Data Flow and
Reproducibility</h2>
<p>QSeaBattle ensures full reproducibility through careful data
management.</p>
<h3 id="tournament-execution">Tournament Execution</h3>
<p>Pseudocode for tournament flow:</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> each game:</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    env.reset()          <span class="co"># New field and gun</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    players.reset()      <span class="co"># Clear player state</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    field, gun <span class="op">=</span> env.provide()</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    comm <span class="op">=</span> playerA.decide(field)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    comm_noisy <span class="op">=</span> env.apply_channel_noise(comm)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    shoot <span class="op">=</span> playerB.decide(gun, comm_noisy)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    reward <span class="op">=</span> env.evaluate(shoot)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    log.update(field, gun, comm, shoot, reward)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> players.has_log_probs:</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>        log.update_log_probs(playerA.get_log_prob(), </span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>                            playerB.get_log_prob())</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> players.has_prev:</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>        log.update_log_prev(playerA.get_prev())</span></code></pre></div>
<h3 id="logged-data">Logged Data</h3>
<p>The TournamentLog captures everything needed for analysis and
training:</p>
<p><strong>Inputs</strong>: field, gun, comm (post-noise)</p>
<p><strong>Outputs</strong>: shoot, reward</p>
<p><strong>Metadata</strong>: game_id, tournament_id, timestamps</p>
<p><strong>Training Data</strong> (optional):</p>
<ul>
<li>logprob_comm, logprob_shoot for policy gradients</li>
<li>prev_measurements, prev_outcomes for assisted players</li>
<li>sample_weight for curriculum learning</li>
</ul>
<h3 id="reproducibility-guarantees">Reproducibility Guarantees</h3>
<ul>
<li>All randomness derives from a single global seed</li>
<li>Logged games can be exactly replayed</li>
<li>Models can be serialized and restored</li>
<li>Training datasets are deterministically generated</li>
</ul>
<h2 id="use-cases">Use Cases</h2>
<h3 id="research-applications">Research Applications</h3>
<p><strong>1. Quantum Advantage Without Quantum Hardware</strong></p>
<ul>
<li>Investigate when quantum-inspired correlations provide benefits</li>
<li>Test predictions from quantum information theory</li>
<li>Explore the classical-quantum boundary</li>
</ul>
<p><strong>2. Multi-Agent Learning</strong></p>
<ul>
<li>Study emergent communication protocols</li>
<li>Compare different coordination mechanisms</li>
<li>Investigate transfer learning from classical to quantum-inspired
agents</li>
</ul>
<p><strong>3. Neural Architecture Design</strong></p>
<ul>
<li>Test structured vs unstructured neural networks</li>
<li>Evaluate importance of inductive biases</li>
<li>Study gradient flow through discrete operations</li>
</ul>
<h3 id="educational-applications">Educational Applications</h3>
<p><strong>1. Introduction to Quantum Games</strong></p>
<ul>
<li>Visualize quantum concepts without mathematics</li>
<li>Interactive experiments with correlations</li>
<li>Hands-on exploration of information limits</li>
</ul>
<p><strong>2. Deep Learning Pedagogy</strong></p>
<ul>
<li>End-to-end differentiable systems</li>
<li>Imitation and reinforcement learning</li>
<li>Custom Keras layers and training loops</li>
</ul>
<h2 id="getting-started">Getting Started</h2>
<h3 id="installation">Installation</h3>
<div class="sourceCode" id="cb4"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Clone the repository</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> clone https://github.com/yourusername/QSeaBattle.git</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> QSeaBattle</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Install dependencies</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install <span class="at">-r</span> requirements.txt</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Install package</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install <span class="at">-e</span> .</span></code></pre></div>
<h3 id="quick-example">Quick Example</h3>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> Q_Sea_Battle <span class="im">import</span> GameLayout, GameEnv, SimplePlayers, Tournament</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Configure the game</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>layout <span class="op">=</span> GameLayout(</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    field_size<span class="op">=</span><span class="dv">8</span>,        <span class="co"># 8x8 battlefield</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    comms_size<span class="op">=</span><span class="dv">1</span>,        <span class="co"># 1 bit of communication</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    enemy_probability<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    channel_noise<span class="op">=</span><span class="fl">0.0</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create environment and players</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>env <span class="op">=</span> GameEnv(layout)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>players <span class="op">=</span> SimplePlayers(layout)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Run a tournament</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>tournament <span class="op">=</span> Tournament(env, players, layout)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>log <span class="op">=</span> tournament.tournament()</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Analyze results</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>mean_reward, std_error <span class="op">=</span> log.outcome()</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Win rate: </span><span class="sc">{</span>mean_reward<span class="sc">:.3f}</span><span class="ss"> ± </span><span class="sc">{</span>std_error<span class="sc">:.3f}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<h3 id="next-steps">Next Steps</h3>
<ul>
<li><strong>Tutorial 1</strong>: Understanding the game mechanics with
deterministic players</li>
<li><strong>Tutorial 2</strong>: Training neural players by imitation
learning</li>
<li><strong>Tutorial 3</strong>: Implementing and training assisted
players</li>
<li><strong>Tutorial 4</strong>: Reinforcement learning and emergent
strategies</li>
<li><strong>Tutorial 5</strong>: Analyzing results and comparing to
theoretical bounds</li>
</ul>
<h2 id="design-philosophy">Design Philosophy</h2>
<p>QSeaBattle is built on several key principles.</p>
<h3 id="modularity">Modularity</h3>
<p>Each component is self-contained and can be tested independently:</p>
<ul>
<li>Game environment independent of players</li>
<li>Player implementations share common interfaces</li>
<li>Training utilities separated from game logic</li>
<li>Easy to add new player types or game variants</li>
</ul>
<h3 id="transparency">Transparency</h3>
<p>All behavior is explicit and inspectable:</p>
<ul>
<li>No hidden state in game mechanics</li>
<li>Full logging of all decisions and outcomes</li>
<li>Deterministic reproducibility from seeds</li>
<li>Clear separation of learned vs fixed components</li>
</ul>
<h3 id="gradual-complexity">Gradual Complexity</h3>
<p>The framework supports learning progressively:</p>
<ul>
<li>Start with simple deterministic baselines</li>
<li>Add learning with classical neural networks</li>
<li>Introduce quantum-inspired structure gradually</li>
<li>Each layer builds on previous understanding</li>
</ul>
<h3 id="research-ready">Research-Ready</h3>
<p>Designed for experimentation and publication:</p>
<ul>
<li>Clean API for custom player implementations</li>
<li>Comprehensive logging for analysis</li>
<li>Serialization for model sharing</li>
<li>Utilities for theoretical comparisons</li>
</ul>
<h2 id="theoretical-foundations">Theoretical Foundations</h2>
<p>QSeaBattle is grounded in several theoretical frameworks.</p>
<h3 id="information-causality">Information Causality</h3>
<p>This principle from quantum foundations states that the amount of
information Bob can learn about Alice’s <span
class="math inline">\(N\)</span>-bit string, given <span
class="math inline">\(m\)</span> bits of communication, is bounded by
<span class="math inline">\(m\)</span>. QSeaBattle provides a testbed
for this bound.</p>
<p>In our setting: With <span class="math inline">\(N = n^2\)</span> and
communication <span class="math inline">\(m\)</span>, classical
strategies cannot exceed certain win rates. Quantum-inspired strategies
can approach but not violate these bounds.</p>
<h3 id="chsh-inequality">CHSH Inequality</h3>
<p>The game mechanics are related to Bell-type inequalities. The
correlation parameter <span
class="math inline">\(p_{\mathrm{high}}\)</span> in shared randomness
can be tuned to reproduce behaviors from:</p>
<ul>
<li>Classical local hidden variables: <span
class="math inline">\(p_{\mathrm{high}} = 0.5\)</span></li>
<li>Quantum mechanics: <span class="math inline">\(p_{\mathrm{high}}
\approx 0.85\)</span></li>
<li>Post-quantum (signaling) theories: <span
class="math inline">\(p_{\mathrm{high}} = 1.0\)</span></li>
</ul>
<h3 id="communication-complexity">Communication Complexity</h3>
<p>The constraint of <span class="math inline">\(m\)</span> bits relates
to classical communication complexity. QSeaBattle explores:</p>
<ul>
<li>How much coordination is possible with limited communication</li>
<li>The value of shared randomness or entanglement</li>
<li>Tradeoffs between computation, communication, and correlation</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>QSeaBattle provides a rich environment for exploring the interplay
between:</p>
<ul>
<li>Classical and quantum information processing</li>
<li>Hand-crafted algorithms and learned strategies</li>
<li>Communication, correlation, and computation</li>
<li>Theory and implementation</li>
</ul>
<p>Whether you are interested in quantum foundations, multi-agent
learning, or neural architecture design, QSeaBattle offers concrete
problems, clean implementations, and connections to deep theoretical
questions.</p>
<p>The framework is designed to be accessible to newcomers while
providing enough depth for advanced research. We hope it serves as a
bridge between different communities and inspires new insights into the
nature of information, correlation, and intelligence.</p>
<p>Ready to explore? Head to the Quick Start Guide or dive into the
Tutorials.</p>
</body>
</html>
