{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "894d3796",
      "metadata": {},
      "source": [
        "# QSeaBattle: Lin Trainable Assisted Imitation Learning (Bootstrap Tutorial)\n",
        "\n",
        "\n",
        "This notebook demonstrates how we bootstrap *trainable assisted players*\n",
        "by imitation learning from a known-correct classical assisted strategy.\n",
        "\n",
        "The goal is **not** to learn a better strategy yet, but to:\n",
        "1. Verify that the Lin neural architecture can exactly reproduce the\n",
        "   classical assisted algorithm.\n",
        "2. Produce a stable initialization for later DIAL / DRU / RL training.\n",
        "3. Validate the measurement–shared randomness–combine decomposition.\n",
        "\n",
        "If this notebook works, the architecture is correct.\n",
        "If it fails, the bug is architectural, not “learning-related”.\n",
        "\n",
        "Invariant:\n",
        "At the end of this notebook, the neural assisted players must match\n",
        "the classical assisted players *bit-for-bit* in sample mode.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "876dbcb6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CWD: c:\\Users\\nly99857\\OneDrive - Philips\\SW Projects\\QSeaBattle\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "def change_to_repo_root(marker: str = \"src\") -> None:\n",
        "    \"\"\"Change CWD to the repository root (parent of `src`).\"\"\"\n",
        "    here = Path.cwd()\n",
        "    for parent in [here] + list(here.parents):\n",
        "        if (parent / marker).is_dir():\n",
        "            os.chdir(parent)\n",
        "            break\n",
        "\n",
        "change_to_repo_root(\"src\")\n",
        "sys.path.append(\"./src\")\n",
        "\n",
        "print(\"CWD:\", Path.cwd())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4ca42de",
      "metadata": {},
      "source": [
        "## Imports\n",
        "We reuse the linear trainable assisted stack and utilities for imitation training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8b88bd17",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow: 2.20.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from Q_Sea_Battle.game_layout import GameLayout\n",
        "from Q_Sea_Battle.game_env import GameEnv\n",
        "from Q_Sea_Battle.tournament import Tournament\n",
        "\n",
        "from Q_Sea_Battle.lin_trainable_assisted_model_a import LinTrainableAssistedModelA\n",
        "from Q_Sea_Battle.lin_trainable_assisted_model_b import LinTrainableAssistedModelB\n",
        "from Q_Sea_Battle.trainable_assisted_players import TrainableAssistedPlayers\n",
        "\n",
        "from Q_Sea_Battle.lin_trainable_assisted_imitation_utils import (\n",
        "    generate_measurement_dataset_a,\n",
        "    generate_measurement_dataset_b,\n",
        "    generate_combine_dataset_a,\n",
        "    generate_combine_dataset_b,\n",
        "    to_tf_dataset,\n",
        "    transfer_assisted_model_a_layer_weights,\n",
        "    transfer_assisted_model_b_layer_weights,\n",
        "    train_layer\n",
        ")\n",
        "\n",
        "print(\"TensorFlow:\", tf.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44738c61",
      "metadata": {},
      "source": [
        "## Game layout and correlation setting\n",
        "\n",
        "We fix a small field (4×4) and a single communication bit (m=1).\n",
        "This regime is chosen deliberately:\n",
        "\n",
        "• n² = 16 is the smallest nontrivial power-of-two field\n",
        "• m = 1 matches the theoretical assisted protocol\n",
        "• p_high controls the strength of the shared randomness correlation\n",
        "\n",
        "Why this matters:\n",
        "The Lin architecture relies on a *single shared randomness call per decision*.\n",
        "Using the smallest valid field makes debugging and verification feasible,\n",
        "while still exercising the full measurement → correlation → parity pipeline.\n",
        "\n",
        "Note:\n",
        "Changing n² or m here does not only scale the problem;\n",
        "it changes the required structure of the combine layers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9ae413c6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n2: 16 m: 1\n"
          ]
        }
      ],
      "source": [
        "FIELD_SIZE = 4\n",
        "COMMS_SIZE = 1\n",
        "\n",
        "# Shared randomness correlation parameter used by your task\n",
        "P_HIGH = 1.0\n",
        "\n",
        "# Dataset / training sizes\n",
        "DATASET_SIZE = 50_000\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS_MEAS = 4 # we can use smaller number of epochs for measurement training, since it is an easier task\n",
        "EPOCHS_COMB = 25\n",
        "\n",
        "# DIAL/DRU training settings\n",
        "SR_MODE_BOOTSTRAP_EVAL = \"sample\"\n",
        "SR_MODE_DIAL_TRAIN = \"expected\"\n",
        "SR_MODE_DIAL_EVAL = \"sample\"\n",
        "\n",
        "SEED = 123\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Folders\n",
        "data_dir = Path(\"notebooks/data\")\n",
        "models_dir = Path(\"notebooks/models\")\n",
        "data_dir.mkdir(parents=True, exist_ok=True)\n",
        "models_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "n2 = FIELD_SIZE * FIELD_SIZE\n",
        "print(\"n2:\", n2, \"m:\", COMMS_SIZE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f93aead",
      "metadata": {},
      "source": [
        "## Generating imitation targets from the classical assisted players\n",
        "\n",
        "In this section we generate datasets using the *deterministic classical\n",
        "assisted strategy*.\n",
        "\n",
        "Why imitation first?\n",
        "• The classical assisted algorithm is provably correct.\n",
        "• It defines exact targets for:\n",
        "  – measurement choices\n",
        "  – shared randomness outcomes\n",
        "  – communication bits\n",
        "  – shoot decisions\n",
        "• Learning from this data isolates architectural errors from optimisation noise.\n",
        "\n",
        "Crucially:\n",
        "The neural models are **not** discovering the strategy here.\n",
        "They are learning to *represent* it.\n",
        "\n",
        "Invariant:\n",
        "The generated dataset encodes exactly one shared-randomness interaction\n",
        "per decision, and this ordering must be preserved throughout training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bf90c6f1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datasets ready.\n"
          ]
        }
      ],
      "source": [
        "# Build layout for data generation (enemy_probability/channel_noise not used by these generators)\n",
        "layout = GameLayout(field_size=FIELD_SIZE, comms_size=COMMS_SIZE)\n",
        "\n",
        "# --- Generate datasets ---\n",
        "ds_meas_a = generate_measurement_dataset_a(layout, num_samples=DATASET_SIZE, seed=SEED)\n",
        "ds_comb_a = generate_combine_dataset_a(layout, num_samples=DATASET_SIZE, seed=SEED + 1)\n",
        "ds_meas_b = generate_measurement_dataset_b(layout, num_samples=DATASET_SIZE, seed=SEED + 2)\n",
        "ds_comb_b = generate_combine_dataset_b(layout, num_samples=DATASET_SIZE, seed=SEED + 3)\n",
        "\n",
        "tfds_meas_a = to_tf_dataset(ds_meas_a, x_keys=[\"field\"], y_key=\"meas_target\", batch_size=BATCH_SIZE, shuffle=True, seed=SEED)\n",
        "tfds_comb_a = to_tf_dataset(ds_comb_a, x_keys=[\"outcomes_a\"], y_key=\"comm_target\", batch_size=BATCH_SIZE, shuffle=True, seed=SEED+1)\n",
        "tfds_meas_b = to_tf_dataset(ds_meas_b, x_keys=[\"gun\"], y_key=\"meas_target\", batch_size=BATCH_SIZE, shuffle=True, seed=SEED+2)\n",
        "tfds_comb_b = to_tf_dataset(ds_comb_b, x_keys=[\"outcomes_b\",\"comm\"], y_key=\"shoot_target\", batch_size=BATCH_SIZE, shuffle=True, seed=SEED+3)\n",
        "\n",
        "print(\"Datasets ready.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72a8508c",
      "metadata": {},
      "source": [
        "## Training individual layers by supervised imitation\n",
        "\n",
        "We train the layers in isolation rather than end-to-end.\n",
        "\n",
        "Why layer-wise training?\n",
        "• The assisted algorithm has a known internal structure.\n",
        "• Measurement layers have *local*, per-cell targets.\n",
        "• Combine layers implement *global parity*, which is hard to learn end-to-end.\n",
        "• Separating them stabilizes training and makes failures diagnosable.\n",
        "\n",
        "Interpretation:\n",
        "Each layer learns a well-defined subroutine of the classical algorithm.\n",
        "\n",
        "Measurement target:\n",
        "Player A measures type-1 exactly on cells where field == 1.\n",
        "Player B measures type-1 exactly at the gun position.\n",
        "\n",
        "These targets are not arbitrary:\n",
        "they are the classical measurement rules expressed in neural form.\n",
        "\n",
        "Combine target:\n",
        "The communication bit (and shoot decision) is the parity (XOR)\n",
        "of the shared-randomness outcomes.\n",
        "\n",
        "This is the nontrivial part of the protocol.\n",
        "If this layer fails to learn parity, the architecture will not scale.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "530bf4ff",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\nly99857\\OneDrive - Philips\\SW Projects\\QSeaBattle\\venvs\\env_QSeaBattle\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "Epoch 1/4\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - binary_accuracy: 0.8428 - loss: 0.4867\n",
            "Epoch 2/4\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - binary_accuracy: 0.9998 - loss: 0.1332\n",
            "Epoch 3/4\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - binary_accuracy: 1.0000 - loss: 0.0423\n",
            "Epoch 4/4\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - binary_accuracy: 1.0000 - loss: 0.0194\n",
            "Epoch 1/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - binary_accuracy: 0.5028 - loss: 0.6947\n",
            "Epoch 2/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - binary_accuracy: 0.5159 - loss: 0.6923\n",
            "Epoch 3/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - binary_accuracy: 0.5370 - loss: 0.6901\n",
            "Epoch 4/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - binary_accuracy: 0.5786 - loss: 0.6817\n",
            "Epoch 5/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - binary_accuracy: 0.6263 - loss: 0.6519\n",
            "Epoch 6/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - binary_accuracy: 0.6769 - loss: 0.6019\n",
            "Epoch 7/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - binary_accuracy: 0.7325 - loss: 0.5374\n",
            "Epoch 8/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - binary_accuracy: 0.7994 - loss: 0.4485\n",
            "Epoch 9/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - binary_accuracy: 0.8672 - loss: 0.3447\n",
            "Epoch 10/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - binary_accuracy: 0.9119 - loss: 0.2600\n",
            "Epoch 11/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - binary_accuracy: 0.9283 - loss: 0.2151\n",
            "Epoch 12/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - binary_accuracy: 0.9397 - loss: 0.1826\n",
            "Epoch 13/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - binary_accuracy: 0.9499 - loss: 0.1556\n",
            "Epoch 14/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - binary_accuracy: 0.9580 - loss: 0.1326\n",
            "Epoch 15/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - binary_accuracy: 0.9651 - loss: 0.1139\n",
            "Epoch 16/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - binary_accuracy: 0.9703 - loss: 0.0997\n",
            "Epoch 17/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - binary_accuracy: 0.9751 - loss: 0.0865\n",
            "Epoch 18/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - binary_accuracy: 0.9782 - loss: 0.0764\n",
            "Epoch 19/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - binary_accuracy: 0.9806 - loss: 0.0679\n",
            "Epoch 20/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - binary_accuracy: 0.9837 - loss: 0.0598\n",
            "Epoch 21/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - binary_accuracy: 0.9859 - loss: 0.0526\n",
            "Epoch 22/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - binary_accuracy: 0.9880 - loss: 0.0455\n",
            "Epoch 23/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - binary_accuracy: 0.9898 - loss: 0.0407\n",
            "Epoch 24/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - binary_accuracy: 0.9914 - loss: 0.0358\n",
            "Epoch 25/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - binary_accuracy: 0.9921 - loss: 0.0324\n",
            "Epoch 1/4\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - binary_accuracy: 0.8952 - loss: 0.3920\n",
            "Epoch 2/4\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - binary_accuracy: 0.9446 - loss: 0.1279\n",
            "Epoch 3/4\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - binary_accuracy: 0.9983 - loss: 0.0430\n",
            "Epoch 4/4\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - binary_accuracy: 1.0000 - loss: 0.0154\n",
            "Epoch 1/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - binary_accuracy: 0.5002 - loss: 0.6948\n",
            "Epoch 2/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - binary_accuracy: 0.5287 - loss: 0.6915\n",
            "Epoch 3/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - binary_accuracy: 0.5580 - loss: 0.6858\n",
            "Epoch 4/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - binary_accuracy: 0.5881 - loss: 0.6730\n",
            "Epoch 5/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - binary_accuracy: 0.6315 - loss: 0.6507\n",
            "Epoch 6/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - binary_accuracy: 0.6875 - loss: 0.6094\n",
            "Epoch 7/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - binary_accuracy: 0.7499 - loss: 0.5473\n",
            "Epoch 8/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - binary_accuracy: 0.8058 - loss: 0.4711\n",
            "Epoch 9/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 31ms/step - binary_accuracy: 0.8610 - loss: 0.3850\n",
            "Epoch 10/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - binary_accuracy: 0.9038 - loss: 0.3022\n",
            "Epoch 11/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - binary_accuracy: 0.9281 - loss: 0.2440\n",
            "Epoch 12/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - binary_accuracy: 0.9426 - loss: 0.2020\n",
            "Epoch 13/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - binary_accuracy: 0.9496 - loss: 0.1742\n",
            "Epoch 14/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - binary_accuracy: 0.9569 - loss: 0.1505\n",
            "Epoch 15/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - binary_accuracy: 0.9625 - loss: 0.1307\n",
            "Epoch 16/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - binary_accuracy: 0.9683 - loss: 0.1143\n",
            "Epoch 17/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - binary_accuracy: 0.9739 - loss: 0.0986\n",
            "Epoch 18/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - binary_accuracy: 0.9786 - loss: 0.0848\n",
            "Epoch 19/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - binary_accuracy: 0.9811 - loss: 0.0753\n",
            "Epoch 20/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - binary_accuracy: 0.9840 - loss: 0.0657\n",
            "Epoch 21/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - binary_accuracy: 0.9860 - loss: 0.0579\n",
            "Epoch 22/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - binary_accuracy: 0.9876 - loss: 0.0525\n",
            "Epoch 23/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - binary_accuracy: 0.9879 - loss: 0.0488\n",
            "Epoch 24/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - binary_accuracy: 0.9905 - loss: 0.0422\n",
            "Epoch 25/25\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - binary_accuracy: 0.9908 - loss: 0.0396\n",
            "Standalone layers trained.\n"
          ]
        }
      ],
      "source": [
        "# --- Train layers ---\n",
        "from Q_Sea_Battle.lin_measurement_layer_a import LinMeasurementLayerA\n",
        "from Q_Sea_Battle.lin_measurement_layer_b import LinMeasurementLayerB\n",
        "from Q_Sea_Battle.lin_combine_layer_a import LinCombineLayerA\n",
        "from Q_Sea_Battle.lin_combine_layer_b import LinCombineLayerB\n",
        "\n",
        "# --- Build layers ---\n",
        "n2 = FIELD_SIZE * FIELD_SIZE\n",
        "model_a = LinTrainableAssistedModelA(\n",
        "    field_size=FIELD_SIZE,\n",
        "    comms_size=COMMS_SIZE,\n",
        "    sr_mode=\"sample\",   # evaluation mode\n",
        "    seed=SEED,\n",
        "    p_high=P_HIGH,\n",
        ")\n",
        "meas_layer_a = model_a.measure_layer\n",
        "comb_layer_a = model_a.combine_layer\n",
        "\n",
        "model_b = LinTrainableAssistedModelB(\n",
        "    field_size=FIELD_SIZE,\n",
        "    comms_size=COMMS_SIZE,\n",
        "    sr_mode=\"sample\",   # evaluation mode\n",
        "    seed=SEED,\n",
        "    p_high=P_HIGH,\n",
        ")\n",
        "meas_layer_b = model_b.measure_layer\n",
        "comb_layer_b = model_b.combine_layer\n",
        "\n",
        "_ = train_layer(meas_layer_a, tfds_meas_a, loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), epochs=EPOCHS_MEAS,\n",
        "                metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5)])\n",
        "_ = train_layer(comb_layer_a, tfds_comb_a, loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), epochs=EPOCHS_COMB,\n",
        "                metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.0)])\n",
        "\n",
        "_ = train_layer(meas_layer_b, tfds_meas_b, loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), epochs=EPOCHS_MEAS,\n",
        "                metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5)])\n",
        "_ = train_layer(comb_layer_b, tfds_comb_b, loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), epochs=EPOCHS_COMB,\n",
        "                metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.0)])\n",
        "\n",
        "print(\"Standalone layers trained.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef71cc2c",
      "metadata": {},
      "source": [
        "## Assembling Model A and Model B\n",
        "\n",
        "After training the components, we assemble the full\n",
        "LinTrainableAssistedModelA and LinTrainableAssistedModelB.\n",
        "\n",
        "Why assembly after training?\n",
        "• It enforces a strict separation between structure and optimisation.\n",
        "• It guarantees that A and B use *the same shared randomness resource*.\n",
        "• It mirrors the exact dataflow of the classical assisted players.\n",
        "\n",
        "At this point, the models are structurally complete.\n",
        "\n",
        "Warning:\n",
        "If Model A and Model B are not perfectly aligned on shared layers,\n",
        "any apparent learning success is meaningless.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "eb2a9afb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installed weights into model_a/model_b\n",
            "model_a sr_mode: sample\n",
            "model_b sr_mode: sample\n"
          ]
        }
      ],
      "source": [
        "# --- Install into full models ---\n",
        "model_a = LinTrainableAssistedModelA(field_size=FIELD_SIZE, comms_size=COMMS_SIZE, sr_mode=SR_MODE_BOOTSTRAP_EVAL, seed=SEED, p_high=P_HIGH)\n",
        "model_b = LinTrainableAssistedModelB(field_size=FIELD_SIZE, comms_size=COMMS_SIZE, sr_mode=SR_MODE_BOOTSTRAP_EVAL, seed=SEED, p_high=P_HIGH)\n",
        "\n",
        "# Build models (required before weight transfer)\n",
        "_ = model_a(tf.zeros((1, n2), tf.float32))\n",
        "_dummy_gun = tf.zeros((1, n2), tf.float32)\n",
        "_dummy_comm = tf.zeros((1, COMMS_SIZE), tf.float32)\n",
        "_dummy_prev_meas_list = [tf.zeros((1, n2), tf.float32)]\n",
        "_dummy_prev_out_list  = [tf.zeros((1, n2), tf.float32)]\n",
        "_ = model_b([_dummy_gun, _dummy_comm, _dummy_prev_meas_list, _dummy_prev_out_list])\n",
        "\n",
        "transfer_assisted_model_a_layer_weights(meas_layer_a, comb_layer_a, model_a)\n",
        "transfer_assisted_model_b_layer_weights(meas_layer_b, comb_layer_b, model_b)\n",
        "\n",
        "print(\"Installed weights into model_a/model_b\")\n",
        "print(\"model_a sr_mode:\", model_a.sr_layer.mode)\n",
        "print(\"model_b sr_mode:\", getattr(model_b, \"sr_layer\", getattr(model_b, \"shared_randomness\", None)).mode)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "129781ad",
      "metadata": {},
      "source": [
        "### Verification: neural vs classical assisted players\n",
        "\n",
        "This is not a performance benchmark.\n",
        "It is a *correctness check*.\n",
        "\n",
        "We compare:\n",
        "• Classical AssistedPlayers\n",
        "• Neural TrainableAssistedPlayers (sample mode)\n",
        "\n",
        "Success criterion:\n",
        "Identical win rates and identical decision statistics within sampling noise.\n",
        "\n",
        "Failure here means:\n",
        "• A broken measurement ordering\n",
        "• Incorrect handling of shared randomness\n",
        "• Or a mismatch in combine logic\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2de321d2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrap tournament over 2000: 1.0000 ± 0.0000\n"
          ]
        }
      ],
      "source": [
        "# Force SR sample explicitly for evaluation\n",
        "model_a.sr_layer.mode = \"sample\"\n",
        "# ModelB may expose sr_layer alias or shared_randomness; handle both.\n",
        "if hasattr(model_b, \"sr_layer\"):\n",
        "    model_b.sr_layer.mode = \"sample\"\n",
        "elif hasattr(model_b, \"shared_randomness\"):\n",
        "    model_b.shared_randomness.mode = \"sample\"\n",
        "\n",
        "players = TrainableAssistedPlayers(layout, model_a=model_a, model_b=model_b)\n",
        "\n",
        "layout_eval = GameLayout(\n",
        "    field_size=FIELD_SIZE,\n",
        "    comms_size=COMMS_SIZE,\n",
        "    enemy_probability=0.5,\n",
        "    channel_noise=0.0,\n",
        "    number_of_games_in_tournament=2_000,\n",
        ")\n",
        "env = GameEnv(layout_eval)\n",
        "t = Tournament(env, players, layout_eval)\n",
        "log = t.tournament()\n",
        "mean_reward, std_err = log.outcome()\n",
        "print(f\"Bootstrap tournament over {layout_eval.number_of_games_in_tournament}: {mean_reward:.4f} ± {std_err:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee1974f2",
      "metadata": {},
      "source": [
        "### Save weights\n",
        "We save weights (not full `.keras` serialization) to avoid custom-object config issues.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "87be7548",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved weights:\n",
            " - notebooks\\models\\lin_model_a_bootstrap_f4_m1_p1.00.weights.h5\n",
            " - notebooks\\models\\lin_model_b_bootstrap_f4_m1_p1.00.weights.h5\n"
          ]
        }
      ],
      "source": [
        "model_a_path = models_dir / f\"lin_model_a_bootstrap_f{FIELD_SIZE}_m{COMMS_SIZE}_p{P_HIGH:.2f}.weights.h5\"\n",
        "model_b_path = models_dir / f\"lin_model_b_bootstrap_f{FIELD_SIZE}_m{COMMS_SIZE}_p{P_HIGH:.2f}.weights.h5\"\n",
        "\n",
        "model_a.save_weights(model_a_path)\n",
        "model_b.save_weights(model_b_path)\n",
        "\n",
        "print(\"Saved weights:\")\n",
        "print(\" -\", model_a_path)\n",
        "print(\" -\", model_b_path)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "kernel_qseabattle",
      "language": "python",
      "name": "kernel_qseabattle"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
