{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "894d3796",
   "metadata": {},
   "source": [
    "# QSeaBattle: Lin Trainable Assisted Imitation Learning (Bootstrap Tutorial)\n",
    "\n",
    "\n",
    "This notebook demonstrates how we bootstrap *trainable assisted players*\n",
    "by imitation learning from a known-correct classical assisted strategy.\n",
    "\n",
    "The goal is **not** to learn a better strategy yet, but to:\n",
    "1. Verify that the Lin neural architecture can exactly reproduce the\n",
    "   classical assisted algorithm.\n",
    "2. Produce a stable initialization for later DIAL / DRU / RL training.\n",
    "3. Validate the measurement–shared resource (SR)–combine decomposition.\n",
    "\n",
    "If this notebook works, the architecture is correct.\n",
    "If it fails, the bug is architectural, not “learning-related”.\n",
    "\n",
    "Invariant:\n",
    "At the end of this notebook, the neural assisted players must match\n",
    "the classical assisted players *bit-for-bit* in sample mode.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "876dbcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: c:\\Users\\nly99857\\OneDrive - Philips\\SW Projects\\QSeaBattle\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def change_to_repo_root(marker: str = \"src\") -> None:\n",
    "    \"\"\"Change CWD to the repository root (parent of `src`).\"\"\"\n",
    "    here = Path.cwd()\n",
    "    for parent in [here] + list(here.parents):\n",
    "        if (parent / marker).is_dir():\n",
    "            os.chdir(parent)\n",
    "            break\n",
    "\n",
    "change_to_repo_root(\"src\")\n",
    "sys.path.append(\"./src\")\n",
    "\n",
    "print(\"CWD:\", Path.cwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ca42de",
   "metadata": {},
   "source": [
    "## Imports\n",
    "We reuse the linear trainable assisted stack and utilities for imitation training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b88bd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from Q_Sea_Battle.game_layout import GameLayout\n",
    "from Q_Sea_Battle.game_env import GameEnv\n",
    "from Q_Sea_Battle.tournament import Tournament\n",
    "\n",
    "from Q_Sea_Battle.lin_trainable_models import LinTrainableAssistedModelA\n",
    "from Q_Sea_Battle.lin_trainable_models import LinTrainableAssistedModelB\n",
    "from Q_Sea_Battle.trainable_assisted_players import TrainableAssistedPlayers\n",
    "\n",
    "from Q_Sea_Battle.lin_trainable_assisted_imitation_utilities import (\n",
    "    generate_measurement_dataset_a,\n",
    "    generate_measurement_dataset_b,\n",
    "    generate_combine_dataset_a,\n",
    "    generate_combine_dataset_b,\n",
    "    to_tf_dataset,\n",
    "    transfer_assisted_model_a_layer_weights,\n",
    "    transfer_assisted_model_b_layer_weights,\n",
    "    train_layer\n",
    ")\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44738c61",
   "metadata": {},
   "source": [
    "## Game layout and correlation setting\n",
    "\n",
    "We fix a small field (4×4) and a single communication bit (m=1).\n",
    "This regime is chosen deliberately:\n",
    "\n",
    "• n² = 16 is the smallest nontrivial power-of-two field\n",
    "• m = 1 matches the theoretical assisted protocol\n",
    "• p_high controls the strength of the shared resource (SR) correlation\n",
    "\n",
    "Why this matters:\n",
    "The Lin architecture relies on a *single shared resource (SR) call per decision*.\n",
    "Using the smallest valid field makes debugging and verification feasible,\n",
    "while still exercising the full measurement → correlation → parity pipeline.\n",
    "\n",
    "Note:\n",
    "Changing n² or m here does not only scale the problem;\n",
    "it changes the required structure of the combine layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ae413c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n2: 16 m: 1\n"
     ]
    }
   ],
   "source": [
    "FIELD_SIZE = 4\n",
    "COMMS_SIZE = 1\n",
    "\n",
    "# shared resource (SR) correlation parameter used by your task\n",
    "P_HIGH = 1.0\n",
    "\n",
    "# Dataset / training sizes\n",
    "DATASET_SIZE = 50_000\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS_MEAS = 4 # we can use smaller number of epochs for measurement training, since it is an easier task\n",
    "EPOCHS_COMB = 25\n",
    "\n",
    "# DIAL/DRU training settings\n",
    "SR_MODE_BOOTSTRAP_EVAL = \"sample\"\n",
    "SR_MODE_DIAL_TRAIN = \"expected\"\n",
    "SR_MODE_DIAL_EVAL = \"sample\"\n",
    "\n",
    "SEED = 123\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Folders\n",
    "data_dir = Path(\"notebooks/data\")\n",
    "models_dir = Path(\"notebooks/models\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "n2 = FIELD_SIZE * FIELD_SIZE\n",
    "print(\"n2:\", n2, \"m:\", COMMS_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f93aead",
   "metadata": {},
   "source": [
    "## Generating imitation targets from the classical assisted players\n",
    "\n",
    "In this section we generate datasets using the *deterministic classical\n",
    "assisted strategy*.\n",
    "\n",
    "Why imitation first?\n",
    "• The classical assisted algorithm is provably correct.\n",
    "• It defines exact targets for:\n",
    "  – measurement choices\n",
    "  – shared resource (SR) outcomes\n",
    "  – communication bits\n",
    "  – shoot decisions\n",
    "• Learning from this data isolates architectural errors from optimisation noise.\n",
    "\n",
    "Crucially:\n",
    "The neural models are **not** discovering the strategy here.\n",
    "They are learning to *represent* it.\n",
    "\n",
    "Invariant:\n",
    "The generated dataset encodes exactly one shared-randomness interaction\n",
    "per decision, and this ordering must be preserved throughout training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf90c6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets ready.\n"
     ]
    }
   ],
   "source": [
    "# Build layout for data generation (enemy_probability/channel_noise not used by these generators)\n",
    "layout = GameLayout(field_size=FIELD_SIZE, comms_size=COMMS_SIZE)\n",
    "\n",
    "# --- Generate datasets ---\n",
    "ds_meas_a = generate_measurement_dataset_a(layout, num_samples=DATASET_SIZE, seed=SEED)\n",
    "ds_comb_a = generate_combine_dataset_a(layout, num_samples=DATASET_SIZE, seed=SEED + 1)\n",
    "ds_meas_b = generate_measurement_dataset_b(layout, num_samples=DATASET_SIZE, seed=SEED + 2)\n",
    "ds_comb_b = generate_combine_dataset_b(layout, num_samples=DATASET_SIZE, seed=SEED + 3)\n",
    "\n",
    "tfds_meas_a = to_tf_dataset(ds_meas_a, x_keys=[\"field\"], y_key=\"meas_target\", batch_size=BATCH_SIZE, shuffle=True, seed=SEED)\n",
    "tfds_comb_a = to_tf_dataset(ds_comb_a, x_keys=[\"outcomes_a\"], y_key=\"comm_target\", batch_size=BATCH_SIZE, shuffle=True, seed=SEED+1)\n",
    "tfds_meas_b = to_tf_dataset(ds_meas_b, x_keys=[\"gun\"], y_key=\"meas_target\", batch_size=BATCH_SIZE, shuffle=True, seed=SEED+2)\n",
    "tfds_comb_b = to_tf_dataset(ds_comb_b, x_keys=[\"outcomes_b\",\"comm\"], y_key=\"shoot_target\", batch_size=BATCH_SIZE, shuffle=True, seed=SEED+3)\n",
    "\n",
    "print(\"Datasets ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a8508c",
   "metadata": {},
   "source": [
    "## Training individual layers by supervised imitation\n",
    "\n",
    "We train the layers in isolation rather than end-to-end.\n",
    "\n",
    "Why layer-wise training?\n",
    "• The assisted algorithm has a known internal structure.\n",
    "• Measurement layers have *local*, per-cell targets.\n",
    "• Combine layers implement *global parity*, which is hard to learn end-to-end.\n",
    "• Separating them stabilizes training and makes failures diagnosable.\n",
    "\n",
    "Interpretation:\n",
    "Each layer learns a well-defined subroutine of the classical algorithm.\n",
    "\n",
    "Measurement target:\n",
    "Player A measures type-1 exactly on cells where field == 1.\n",
    "Player B measures type-1 exactly at the gun position.\n",
    "\n",
    "These targets are not arbitrary:\n",
    "they are the classical measurement rules expressed in neural form.\n",
    "\n",
    "Combine target:\n",
    "The communication bit (and shoot decision) is the parity (XOR)\n",
    "of the shared-randomness outcomes.\n",
    "\n",
    "This is the nontrivial part of the protocol.\n",
    "If this layer fails to learn parity, the architecture will not scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "530bf4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\nly99857\\OneDrive - Philips\\SW Projects\\QSeaBattle\\venvs\\env_QSeaBattle\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Epoch 1/4\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - binary_accuracy: 0.8626 - loss: 0.4615\n",
      "Epoch 2/4\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - binary_accuracy: 0.9997 - loss: 0.1260\n",
      "Epoch 3/4\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - binary_accuracy: 1.0000 - loss: 0.0403\n",
      "Epoch 4/4\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - binary_accuracy: 1.0000 - loss: 0.0184\n",
      "Epoch 1/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 41ms/step - binary_accuracy: 0.5041 - loss: 0.6941\n",
      "Epoch 2/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - binary_accuracy: 0.5145 - loss: 0.6925\n",
      "Epoch 3/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - binary_accuracy: 0.5412 - loss: 0.6883\n",
      "Epoch 4/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - binary_accuracy: 0.5802 - loss: 0.6769\n",
      "Epoch 5/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - binary_accuracy: 0.6340 - loss: 0.6462\n",
      "Epoch 6/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - binary_accuracy: 0.6996 - loss: 0.5887\n",
      "Epoch 7/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - binary_accuracy: 0.7629 - loss: 0.5112\n",
      "Epoch 8/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - binary_accuracy: 0.8092 - loss: 0.4398\n",
      "Epoch 9/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - binary_accuracy: 0.8538 - loss: 0.3696\n",
      "Epoch 10/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - binary_accuracy: 0.8926 - loss: 0.3026\n",
      "Epoch 11/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - binary_accuracy: 0.9175 - loss: 0.2517\n",
      "Epoch 12/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - binary_accuracy: 0.9368 - loss: 0.2081\n",
      "Epoch 13/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - binary_accuracy: 0.9502 - loss: 0.1751\n",
      "Epoch 14/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - binary_accuracy: 0.9631 - loss: 0.1426\n",
      "Epoch 15/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - binary_accuracy: 0.9693 - loss: 0.1197\n",
      "Epoch 16/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - binary_accuracy: 0.9736 - loss: 0.1035\n",
      "Epoch 17/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - binary_accuracy: 0.9786 - loss: 0.0873\n",
      "Epoch 18/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - binary_accuracy: 0.9801 - loss: 0.0784\n",
      "Epoch 19/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - binary_accuracy: 0.9829 - loss: 0.0700\n",
      "Epoch 20/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - binary_accuracy: 0.9836 - loss: 0.0643\n",
      "Epoch 21/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - binary_accuracy: 0.9858 - loss: 0.0590\n",
      "Epoch 22/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - binary_accuracy: 0.9865 - loss: 0.0543\n",
      "Epoch 23/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - binary_accuracy: 0.9886 - loss: 0.0493\n",
      "Epoch 24/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - binary_accuracy: 0.9882 - loss: 0.0478\n",
      "Epoch 25/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - binary_accuracy: 0.9892 - loss: 0.0434\n",
      "Epoch 1/4\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - binary_accuracy: 0.8968 - loss: 0.3909\n",
      "Epoch 2/4\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - binary_accuracy: 0.9442 - loss: 0.1299\n",
      "Epoch 3/4\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - binary_accuracy: 0.9990 - loss: 0.0419\n",
      "Epoch 4/4\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - binary_accuracy: 1.0000 - loss: 0.0148\n",
      "Epoch 1/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - binary_accuracy: 0.5031 - loss: 0.6942\n",
      "Epoch 2/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - binary_accuracy: 0.5143 - loss: 0.6929\n",
      "Epoch 3/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - binary_accuracy: 0.5190 - loss: 0.6922\n",
      "Epoch 4/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - binary_accuracy: 0.5382 - loss: 0.6894\n",
      "Epoch 5/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - binary_accuracy: 0.5862 - loss: 0.6776\n",
      "Epoch 6/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - binary_accuracy: 0.6343 - loss: 0.6472\n",
      "Epoch 7/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - binary_accuracy: 0.6875 - loss: 0.5989\n",
      "Epoch 8/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - binary_accuracy: 0.7638 - loss: 0.5178\n",
      "Epoch 9/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - binary_accuracy: 0.8164 - loss: 0.4349\n",
      "Epoch 10/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - binary_accuracy: 0.8534 - loss: 0.3659\n",
      "Epoch 11/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - binary_accuracy: 0.8822 - loss: 0.3072\n",
      "Epoch 12/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - binary_accuracy: 0.9139 - loss: 0.2490\n",
      "Epoch 13/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - binary_accuracy: 0.9412 - loss: 0.1914\n",
      "Epoch 14/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - binary_accuracy: 0.9541 - loss: 0.1546\n",
      "Epoch 15/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - binary_accuracy: 0.9629 - loss: 0.1296\n",
      "Epoch 16/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - binary_accuracy: 0.9689 - loss: 0.1117\n",
      "Epoch 17/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - binary_accuracy: 0.9731 - loss: 0.0979\n",
      "Epoch 18/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - binary_accuracy: 0.9747 - loss: 0.0888\n",
      "Epoch 19/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - binary_accuracy: 0.9780 - loss: 0.0788\n",
      "Epoch 20/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - binary_accuracy: 0.9805 - loss: 0.0711\n",
      "Epoch 21/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - binary_accuracy: 0.9808 - loss: 0.0668\n",
      "Epoch 22/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - binary_accuracy: 0.9825 - loss: 0.0615\n",
      "Epoch 23/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - binary_accuracy: 0.9837 - loss: 0.0575\n",
      "Epoch 24/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - binary_accuracy: 0.9844 - loss: 0.0536\n",
      "Epoch 25/25\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - binary_accuracy: 0.9862 - loss: 0.0501\n",
      "Standalone layers trained.\n"
     ]
    }
   ],
   "source": [
    "# --- Train layers ---\n",
    "from Q_Sea_Battle.lin_teacher_layers import LinMeasurementLayerA\n",
    "from Q_Sea_Battle.lin_teacher_layers import LinMeasurementLayerB\n",
    "from Q_Sea_Battle.lin_teacher_layers import LinCombineLayerA\n",
    "from Q_Sea_Battle.lin_teacher_layers import LinCombineLayerB\n",
    "\n",
    "# --- Build layers ---\n",
    "n2 = FIELD_SIZE * FIELD_SIZE\n",
    "model_a = LinTrainableAssistedModelA(\n",
    "    field_size=FIELD_SIZE,\n",
    "    comms_size=COMMS_SIZE,\n",
    "    sr_mode=\"sample\",   # evaluation mode\n",
    "    seed=SEED,\n",
    "    p_high=P_HIGH,\n",
    ")\n",
    "meas_layer_a = model_a.measure_layer\n",
    "comb_layer_a = model_a.combine_layer\n",
    "\n",
    "model_b = LinTrainableAssistedModelB(\n",
    "    field_size=FIELD_SIZE,\n",
    "    comms_size=COMMS_SIZE,\n",
    "    sr_mode=\"sample\",   # evaluation mode\n",
    "    seed=SEED,\n",
    "    p_high=P_HIGH,\n",
    ")\n",
    "meas_layer_b = model_b.measure_layer\n",
    "comb_layer_b = model_b.combine_layer\n",
    "\n",
    "_ = train_layer(meas_layer_a, tfds_meas_a, loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), epochs=EPOCHS_MEAS,\n",
    "                metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5)])\n",
    "_ = train_layer(comb_layer_a, tfds_comb_a, loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), epochs=EPOCHS_COMB,\n",
    "                metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.0)])\n",
    "\n",
    "_ = train_layer(meas_layer_b, tfds_meas_b, loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), epochs=EPOCHS_MEAS,\n",
    "                metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5)])\n",
    "_ = train_layer(comb_layer_b, tfds_comb_b, loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), epochs=EPOCHS_COMB,\n",
    "                metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.0)])\n",
    "\n",
    "print(\"Standalone layers trained.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef71cc2c",
   "metadata": {},
   "source": [
    "## Assembling Model A and Model B\n",
    "\n",
    "After training the components, we assemble the full\n",
    "LinTrainableAssistedModelA and LinTrainableAssistedModelB.\n",
    "\n",
    "Why assembly after training?\n",
    "• It enforces a strict separation between structure and optimisation.\n",
    "• It guarantees that A and B use *the same shared resource (SR) resource*.\n",
    "• It mirrors the exact dataflow of the classical assisted players.\n",
    "\n",
    "At this point, the models are structurally complete.\n",
    "\n",
    "Warning:\n",
    "If Model A and Model B are not perfectly aligned on shared layers,\n",
    "any apparent learning success is meaningless.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb2a9afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed weights into model_a/model_b\n",
      "model_a sr_mode: sample\n",
      "model_b sr_mode: sample\n"
     ]
    }
   ],
   "source": [
    "# --- Install into full models ---\n",
    "model_a = LinTrainableAssistedModelA(field_size=FIELD_SIZE, comms_size=COMMS_SIZE, sr_mode=SR_MODE_BOOTSTRAP_EVAL, seed=SEED, p_high=P_HIGH)\n",
    "model_b = LinTrainableAssistedModelB(field_size=FIELD_SIZE, comms_size=COMMS_SIZE, sr_mode=SR_MODE_BOOTSTRAP_EVAL, seed=SEED, p_high=P_HIGH)\n",
    "\n",
    "# Build models (required before weight transfer)\n",
    "_ = model_a(tf.zeros((1, n2), tf.float32))\n",
    "_dummy_gun = tf.zeros((1, n2), tf.float32)\n",
    "_dummy_comm = tf.zeros((1, COMMS_SIZE), tf.float32)\n",
    "_dummy_prev_meas_list = [tf.zeros((1, n2), tf.float32)]\n",
    "_dummy_prev_out_list  = [tf.zeros((1, n2), tf.float32)]\n",
    "_ = model_b([_dummy_gun, _dummy_comm, _dummy_prev_meas_list, _dummy_prev_out_list])\n",
    "\n",
    "transfer_assisted_model_a_layer_weights(meas_layer_a, comb_layer_a, model_a)\n",
    "transfer_assisted_model_b_layer_weights(meas_layer_b, comb_layer_b, model_b)\n",
    "\n",
    "print(\"Installed weights into model_a/model_b\")\n",
    "print(\"model_a sr_mode:\", model_a.sr_layer.mode)\n",
    "print(\"model_b sr_mode:\", getattr(model_b, \"sr_layer\", getattr(model_b, \"shared_randomness\", None)).mode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129781ad",
   "metadata": {},
   "source": [
    "### Verification: neural vs classical assisted players\n",
    "\n",
    "This is not a performance benchmark.\n",
    "It is a *correctness check*.\n",
    "\n",
    "We compare:\n",
    "• Classical AssistedPlayers\n",
    "• Neural TrainableAssistedPlayers (sample mode)\n",
    "\n",
    "Success criterion:\n",
    "Identical win rates and identical decision statistics within sampling noise.\n",
    "\n",
    "Failure here means:\n",
    "• A broken measurement ordering\n",
    "• Incorrect handling of shared resource (SR)\n",
    "• Or a mismatch in combine logic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2de321d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap tournament over 2000: 1.0000 ± 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Force SR sample explicitly for evaluation\n",
    "model_a.sr_layer.mode = \"sample\"\n",
    "# ModelB may expose sr_layer alias or shared_randomness; handle both.\n",
    "if hasattr(model_b, \"sr_layer\"):\n",
    "    model_b.sr_layer.mode = \"sample\"\n",
    "elif hasattr(model_b, \"shared_randomness\"):\n",
    "    model_b.shared_randomness.mode = \"sample\"\n",
    "\n",
    "players = TrainableAssistedPlayers(layout, model_a=model_a, model_b=model_b)\n",
    "\n",
    "layout_eval = GameLayout(\n",
    "    field_size=FIELD_SIZE,\n",
    "    comms_size=COMMS_SIZE,\n",
    "    enemy_probability=0.5,\n",
    "    channel_noise=0.0,\n",
    "    number_of_games_in_tournament=2_000,\n",
    ")\n",
    "env = GameEnv(layout_eval)\n",
    "t = Tournament(env, players, layout_eval)\n",
    "log = t.tournament()\n",
    "mean_reward, std_err = log.outcome()\n",
    "print(f\"Bootstrap tournament over {layout_eval.number_of_games_in_tournament}: {mean_reward:.4f} ± {std_err:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1974f2",
   "metadata": {},
   "source": [
    "### Save weights\n",
    "We save weights (not full `.keras` serialization) to avoid custom-object config issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87be7548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved weights:\n",
      " - notebooks\\models\\lin_model_a_bootstrap_f4_m1_p1.00.weights.h5\n",
      " - notebooks\\models\\lin_model_b_bootstrap_f4_m1_p1.00.weights.h5\n"
     ]
    }
   ],
   "source": [
    "model_a_path = models_dir / f\"lin_model_a_bootstrap_f{FIELD_SIZE}_m{COMMS_SIZE}_p{P_HIGH:.2f}.weights.h5\"\n",
    "model_b_path = models_dir / f\"lin_model_b_bootstrap_f{FIELD_SIZE}_m{COMMS_SIZE}_p{P_HIGH:.2f}.weights.h5\"\n",
    "\n",
    "model_a.save_weights(model_a_path)\n",
    "model_b.save_weights(model_b_path)\n",
    "\n",
    "print(\"Saved weights:\")\n",
    "print(\" -\", model_a_path)\n",
    "print(\" -\", model_b_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel_qseabattle",
   "language": "python",
   "name": "kernel_qseabattle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
